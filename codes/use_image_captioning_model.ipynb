{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_image_captioning_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJY-57QnuI21",
        "colab_type": "code",
        "outputId": "1c07a131-8d04-4949-84bf-787513ceb6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKuOYJ6lv-rj",
        "colab_type": "code",
        "outputId": "14fedac2-e723-4206-933f-eb31c253431a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "path='drive/My Drive/deep_proj/' #for new data change the path\n",
        "image_model_transfer=load_model(path+'image_model_transfer.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3iEv8k48MKR",
        "colab_type": "code",
        "outputId": "265b8a87-a3c2-4e42-da16-ec7d28f1dfe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open(path+'decoder_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "decoder_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "decoder_model.load_weights(path+\"decoder_model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b51Rk-kJwRF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "# loading tokenizer\n",
        "with open(path+'tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAI1d5rYVGL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open(path+'image_captioning_info.json') as json_file:\n",
        "    image_captioning_info = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc98TJeuAlb1",
        "colab_type": "code",
        "outputId": "876f35e5-1994-4693-ce71-3c49ed1d0132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "pip install pygame"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv8-LR5Y9l8C",
        "colab_type": "code",
        "outputId": "854f8dc4-72c1-4a55-b1ac-b2bf3faf66ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#load test data\n",
        "import io, pygame\n",
        "import zipfile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "image_number=39 #len(image_captioning_info)\n",
        "data_set=np.zeros([image_number,224,224,3],dtype='uint8')\n",
        "file_path=path+'captioning_images.zip'\n",
        "\n",
        "labels=[]\n",
        "archive = zipfile.ZipFile(file_path, 'r')\n",
        "ind=0\n",
        "for index in range(image_number):\n",
        "    imgdata = archive.read(str(index+1)+'.jpg')  # image_captioning_info[index]['file_name']\n",
        "\n",
        "    # create a pygame-compatible file-like object from the bytes\n",
        "    bytes_io = io.BytesIO(imgdata)\n",
        "    img = pygame.image.load(bytes_io)\n",
        "    imgg = pygame.surfarray.array3d(img)\n",
        "    final=imgg.swapaxes(0,1)\n",
        "    resized = cv2.resize(final, (224,224), interpolation = cv2.INTER_AREA)\n",
        "    data_set[index,:,:,:] = resized\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aho14TLQL3SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "data_set_preprocessed = keras.applications.xception.preprocess_input(data_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1NWarhQLZFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def generate_caption(im_idx, max_tokens=30):\n",
        "\n",
        "    # Load the image.\n",
        "    image = data_set_preprocessed[im_idx]\n",
        "    \n",
        "    # Expand the 3-dim numpy array to 4-dim\n",
        "    # because the image-model expects a whole batch as input,\n",
        "    # so we give it a batch with just one image.\n",
        "    image_batch = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Process the image with the pre-trained image-model\n",
        "    # to get the transfer-values.\n",
        "    transfer_values = image_model_transfer.predict(image_batch)\n",
        "\n",
        "    # Pre-allocate the 2-dim array used as input to the decoder.\n",
        "    # This holds just a single sequence of integer-tokens,\n",
        "    # but the decoder-model expects a batch of sequences.\n",
        "    shape = (1, max_tokens)\n",
        "    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n",
        "\n",
        "    # The first input-token is the special start-token \n",
        "    token_int = tokenizer.word_index['<start>']\n",
        "\n",
        "    # Initialize an empty output-text.\n",
        "    output_text = ''\n",
        "\n",
        "    # Initialize the number of tokens we have processed.\n",
        "    count_tokens = 0\n",
        "\n",
        "    # While we haven't sampled the special end-token \n",
        "    # and we haven't processed the max number of tokens.\n",
        "    while token_int != tokenizer.word_index['<end>'] and count_tokens < max_tokens:\n",
        "        # Update the input-sequence to the decoder\n",
        "        # with the last token that was sampled.\n",
        "        # In the first iteration this will set the\n",
        "        # first element to the start-token.\n",
        "        decoder_input_data[0, count_tokens] = token_int\n",
        "\n",
        "        # Wrap the input-data in a dict for clarity and safety,\n",
        "        # so we are sure we input the data in the right order.\n",
        "        x_data = \\\n",
        "        {\n",
        "            'transfer_values_input': transfer_values,\n",
        "            'decoder_input': decoder_input_data\n",
        "        }\n",
        "\n",
        "     \n",
        "        \n",
        "        # Input this data to the decoder and get the predicted output.\n",
        "        decoder_output = decoder_model.predict(x_data)\n",
        "\n",
        "        # Get the last predicted token as a one-hot encoded array.\n",
        "        # Note that this is not limited by softmax, but we just\n",
        "        # need the index of the largest element so it doesn't matter.\n",
        "        token_onehot = decoder_output[0, count_tokens, :]\n",
        "\n",
        "        # Convert to an integer-token.\n",
        "        token_int = np.argmax(token_onehot)\n",
        "\n",
        "        # Lookup the word corresponding to this integer-token.\n",
        "        sampled_word = tokenizer.index_word[token_int]\n",
        "\n",
        "        # Append the word to the output-text.\n",
        "        output_text += \" \" + sampled_word\n",
        "\n",
        "        # Increment the token-counter.\n",
        "        count_tokens += 1\n",
        "\n",
        "    # This is the sequence of tokens output by the decoder.\n",
        "    output_tokens = decoder_input_data[0]\n",
        "\n",
        "    # Plot the image.\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "    # Print the predicted caption.\n",
        "    print(\"Predicted caption:\")\n",
        "    print(output_text)\n",
        "    print()\n",
        "    return output_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVlQHvSNA5uV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_captions=[]\n",
        "for i in range(data_set.shape[0]):\n",
        "    caption=generate_caption(i)\n",
        "    generated_captions.append(caption)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr9uI8lSWmy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/deep_proj/captions.txt', 'w') as output:\n",
        "    output.write(str(generated_captions))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}